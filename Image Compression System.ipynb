{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Compression System\n",
    "\n",
    "<img src=\"img1.png\">\n",
    "\n",
    "## Context & Problem\n",
    "Machine Learning (ML) applications in computer vision is growing faster than ever. Although computing power of modern computers increases, so does the amount of data generated by numerous high-quality pictures. Therefore, efficient large-scale image processing is therefore a challenging task for domestic computers.\n",
    "\n",
    "Imagine a picture size of 1920 x 1200 pixels, pretty common for modern cameras.\n",
    "Each pixel is usually encoded with a red, green, and blue level. This means that a single picture represented in a matrix form would have easily 6.9 millions elements. Now imaging the number of pictures examples required to achieve high-accuracy for a Deep Learning neural network classifiers (> 10,000). This means that overall, we have to feed the learning algorithm with about **70 bilions elements!!** \n",
    "\n",
    "This is not very practical and would not run in a timely manner. Hopefully, although advanced ML algorithms need a lot of picture examples, they do not necessary require such high-quality image for the learning task. \n",
    "## Need & Motivation\n",
    "This Image Compression System project (ICS) originates from the following need:\n",
    "- to have an image pre-processing program that reduces the overall size of any image and constrain the number of usefull colors to its minimum (i.e. such as to retain the necessary level of information for the learning task).\n",
    "\n",
    "This is motivated by the numerous applications it would have on further computer vision related projects, and the time saving once successfully implemented.\n",
    "\n",
    "\n",
    "## Objective & Requirements\n",
    "The **objective** is to implement various image reduction strategies in order to program an Image Compression System (ICS) based on K-means clustering algorithms.\n",
    "\n",
    "The ICS shall meet the following requirements:\n",
    "1. The ICS shall provide the user the choice to reduce the inputed images with the following strategies:\n",
    "    1. Full K-Means clustering algorithm from sklearn library (FKM)\n",
    "    2. Mini-batch K-Means clustering algorithm from sklearn libary (MBKM)\n",
    "    3. Custom-build K-means clustering algorithm (MKM)\n",
    "    4. Size-only compression (only reduce image size, no run of k-means). (SO)\n",
    "2. Whaterver the compression strategy selected by the user is, the ICS shall run a Size-Only reduction on all inputed images.\n",
    "3. The ICS shall take as input multiple images from the local folder \"Uncompressed\", process each image and save as output the compressed image in the local folder \"Compressed\".\n",
    "4. The ICS shall return to the user the images processing progress, and the total program run time.\n",
    "5. When a user selects a K-means clustering strategy (FKM, MBKM, or FKM), the ICS shall request from the user, the number of colors. This number will be applied for the whole image dataset, and represent the K clusters of the K-means algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means clustering in a nutschell\n",
    "In this project, the K-means algorithm is used in order to reduce the maximum number of colors use to encode the picture. Typical pictures are encoded by 255 levels of red, green, and blue, which make more than 16 millions colors possible. A reduce set of colors, allows to compress more efficiently a picture, because it requires a lower number of bits to be encoded.\n",
    "\n",
    "let's imaging we have a 100 pixels image whose x, and y encode Red and Green levels (we omit Blue level for ease of representation in 2D). There are roughly 100 colors to store.\n",
    "<img src=\"img2.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A k-means algorithm is:\n",
    "1. randomly select k pre-defined centroids. (in this project, k is the number of colors)\n",
    "\n",
    "Then iterate:\n",
    "2. Given the centroids of the futur k-clusters, assign the data point to the closest centroid.\n",
    "3. Given data points assignement, update the centroid position using the mean."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "Running a k-means algorithm trying to keep only 4 colors (k=4), would cluster the pixels as follow (cluster centroids are marked in red):\n",
    "1. highly green, low red\n",
    "2. highly green, highly red\n",
    "3. moderate green, highly red\n",
    "4. low green, moderate red.\n",
    "<img src=\"img3.png\">\n",
    "\n",
    "The algorithm of K-means clustering works as follow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom K-Means algorithm\n",
    "In this section, we build our own functions for a custom K-means algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_K_centroids(X,K):\n",
    "    \"\"\" We choose K points from X at random\n",
    "    INPUTS:\n",
    "        - X: (m x n) matrix. Each row correspond to an example (pixel), each column to R,G or B\n",
    "        - K: (scalar). The number of centroids we wish to initialise.\n",
    "    OUTPUT:\n",
    "        - Return the coordinate of the randomly selected K points from K\n",
    "    \"\"\"\n",
    "    # counts how many examples (data points) there are\n",
    "    m = len(X)\n",
    "    \n",
    "    # Create an array of K indices in the range (0 - number of examples)\n",
    "    idx = np.random.choice(m,size=K,replace=False)\n",
    "    \n",
    "    # Return only the randomly selected K points from X\n",
    "    return X[idx]\n",
    "\n",
    "def find_closest_centroids(X,centroids):\n",
    "    \"\"\"For each data point, find what is the closest centroid\n",
    "    INPUTS:\n",
    "        - X: (m x n) matrix. each row corresponds to an example (pixel), each column to R,G or B\n",
    "        - centroids (k x n): each row correspond to a centroid and contains its coordinates\n",
    "    OUTPUT:\n",
    "        - c: (m x 1) vector. each row correspond to the assignment of a pixel to a cluster.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Compute distances for each point to each centroids\n",
    "    \n",
    "    #pre-allocation\n",
    "    difference = np.zeros((centroids.shape[0],X.shape[0],X.shape[1])) \n",
    "    # compute result and store in a new dim(axis=2) \n",
    "    difference = X - centroids[:,np.newaxis]\n",
    "    # pre-allocate distances matrix\n",
    "    distances = np.zeros((centroids.shape[0],X.shape[0]))\n",
    "    # computes distances\n",
    "    distances = np.sqrt(np.sum(np.square(difference),axis=2)) \n",
    "    \n",
    "    # Step2 : Assign closest cluster to each data point is vector c\n",
    "    c = np.argmin(distances,axis=0)\n",
    "    return c\n",
    "\n",
    "def compute_means(X,c,K):\n",
    "    \"\"\"For each cluster of assigned datapoints, compute the mean to update the centroids\n",
    "    INPUTS:\n",
    "        - X: (m x n) matrix. Each row correspond to an example (pixel), each column to R,G or B\n",
    "        - K: (scalar). The number of centroids we wish to initialise.\n",
    "    OUTPUT:\n",
    "        - centroids (k x n): updated position of the cluster centroids \n",
    "    \"\"\"\n",
    "    m,n = X.shape\n",
    "    centroids = np.zeros((K,n)) # pre-allocate the centroids\n",
    "    for k in range(K):    # for each cluster...\n",
    "        examples = X[c==k] # we keep the data points that belongs to this cluster ...\n",
    "        mean = np.mean(examples,axis=0) # ... and compute the mean.\n",
    "        centroids[k]=mean # then we update the centroid position\n",
    "    return centroids\n",
    "\n",
    "def k_means(X,K,max_iters = 10):\n",
    "    \"\"\"\n",
    "    Run custom k-means algorithm on the dataset\n",
    "    INPUTS:\n",
    "        - X (n x d) data points\n",
    "        - K (scalar), the number of cluster\n",
    "        - max_iters, number of repeated cluster assignment and centroid update\n",
    "    OUTPUTS:\n",
    "        - centroids of each cluster\n",
    "        - c (n x 1) vector with assigned cluster to each data point\n",
    "    \"\"\"\n",
    "    centroids = initialize_K_centroids(X,K)\n",
    "    for i in range(max_iters):\n",
    "        c = find_closest_centroids(X,centroids)\n",
    "        centroids = compute_means(X,c,K)\n",
    "    return centroids,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs Request\n",
    "The following piece of code ensure compliance with requirements [1] and [2] It request to the user which image compression strategy should be applied to the set of uncompressed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Choose the Compression Algorithm:\n",
      "Type 'SO' for Size-Only compression\n",
      "Type 'MKM' for Custom K-Means compression\n",
      "Type 'FKM' for sklearn Full K-Means compression\n",
      "Type 'MBKM' for sklearn Mini-Batch K-Means compression\n",
      "Type here :  MBKM\n",
      "Enter the number of colors used after compression:  16\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Choose the Compression Algorithm:\")\n",
    "print(\"Type 'SO' for Size-Only compression\")\n",
    "print(\"Type 'MKM' for Custom K-Means compression\")\n",
    "print(\"Type 'FKM' for sklearn Full K-Means compression\")\n",
    "print(\"Type 'MBKM' for sklearn Mini-Batch K-Means compression\")\n",
    "algo = input(\"Type here :  \")\n",
    "\n",
    "# The the selected algorithm is \"SO\" (i.e. size-only), there will not color clustering.\n",
    "# it is therefore not necessary to ask to the user the number of colors after compression.\n",
    "if algo != \"SO\":\n",
    "    K = int(input(\"Enter the number of colors used after compression:  \"))\n",
    "\n",
    "# Choose and open the current working directory\n",
    "os.chdir(\"/Users/patrickfleith/Desktop/2_DataScience /Projects/ICS\")\n",
    "folderPath = os.getcwd() # get the current working directory\n",
    "originPath = folderPath + \"/Uncompressed\" # create path to the uncompressed data set\n",
    "destinationPath = folderPath + \"/Compressed\" # create path to the compressed folder\n",
    "os.chdir(originPath) # choose and open the folder with uncompressed images\n",
    "image_list = os.listdir(originPath) # make a list of all image names\n",
    "image_list.remove(\".DS_Store\") # remove non image name\n",
    "\n",
    "count = 0 # count will track the number of image already procssed. Initially set to zero.\n",
    "maxCount = len(image_list) # max number of image to be compressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-batch sklearn k-means operation took:  5 s\n",
      "Progress =  17 %\n",
      "Mini-batch sklearn k-means operation took:  5 s\n",
      "Progress =  33 %\n",
      "Mini-batch sklearn k-means operation took:  2 s\n",
      "Progress =  50 %\n",
      "Mini-batch sklearn k-means operation took:  5 s\n",
      "Progress =  67 %\n",
      "Mini-batch sklearn k-means operation took:  8 s\n",
      "Progress =  83 %\n",
      "Mini-batch sklearn k-means operation took:  7 s\n",
      "Progress =  100 %\n",
      "Total Runtime:  34 s\n"
     ]
    }
   ],
   "source": [
    "ti = time.perf_counter() # store initial timer time\n",
    "\n",
    "# For all images in the uncompressed folder\n",
    "for file in image_list:\n",
    "    im = Image.open(file) # open image\n",
    "    image = np.asarray(im) # convert into a numpy array\n",
    "    \n",
    "    # Size reduction\n",
    "    image = image[0:-1:5,0:-1:5,:] # reduce the image size (requirement [2]) by keeping only\\\n",
    "    # 1 pixel every 5 pixel in a row, and 1 pixel every 5 pixel in each columns.\n",
    "    \n",
    "    # If algorithm is Size-Only\n",
    "    if algo == \"SO\":\n",
    "        \n",
    "        compressed_image = Image.fromarray(image)  # convert to Image object\n",
    "        compressed_image.save(destinationPath+\"/\"+str(count)+\".png\") # save the image\n",
    "    \n",
    "    # otherwise, if algorithm is the custom K-means algorithm\n",
    "    elif algo == \"MKM\":\n",
    "        \n",
    "        image = image/255 # normalise image values\n",
    "        w,h,d = image.shape\n",
    "        X = image.reshape((w * h, d)) # reshape the 3d array into a 2d array.\n",
    "        \n",
    "        start = time.perf_counter() # start the timer for processing of this image.\n",
    "        colors, c = k_means(X, K, max_iters=10) # run the custom k-means function.\n",
    "        \n",
    "        # once k-means done, display image processing time\n",
    "        print(\"Costum k-means operation took: \",round(time.perf_counter()-start),\"s\")\n",
    "        \n",
    "        # convert result value in type uint8\n",
    "        c = np.array(c, dtype=np.uint8)\n",
    "        \n",
    "        # reconstruct the image into a 3d array\n",
    "        X_reconstructed = np.array(colors[c, :] * 255, dtype=np.uint8).reshape((w, h, d))\n",
    "        \n",
    "        # convert numpy reconstructed image into an Image object\n",
    "        compressed_image = Image.fromarray(X_reconstructed)\n",
    "        \n",
    "        # save the Image.\n",
    "        compressed_image.save(destinationPath+\"/\"+str(count)+\".png\")\n",
    "    \n",
    "    # otherwise, if the strategy selected was full k-means with sklearn\n",
    "    elif algo == \"FKM\":\n",
    "        \n",
    "        image = image/255\n",
    "        w,h,d = image.shape\n",
    "        X = image.reshape((w * h, d))\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        kmeans = KMeans(n_clusters=K).fit(X) # apply KMeans() from sklearn libary\n",
    "        c = kmeans.labels_ # retrieve data point assignments to clusters\n",
    "        colors = kmeans.cluster_centers_ # retrive centroids coordinates\n",
    "        \n",
    "        # print run time for that given image\n",
    "        print(\"Full sklearn k-means operation took: \",round(time.perf_counter()-start),\"s\")\n",
    "        \n",
    "        # reconstruct and save the image\n",
    "        c = np.array(c, dtype=np.uint8)\n",
    "        X_reconstructed = np.array(colors[c, :] * 255, dtype=np.uint8).reshape((w, h, d))\n",
    "        compressed_image = Image.fromarray(X_reconstructed)\n",
    "        \n",
    "        compressed_image.save(destinationPath+\"/\"+str(count)+\".png\")\n",
    "    \n",
    "    # otherwise, if selected strategy was mini-batch k-means\n",
    "    elif algo == \"MBKM\":\n",
    "        \n",
    "        image = image/255\n",
    "        w,h,d = image.shape\n",
    "        X = image.reshape((w * h, d))\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        kmeans = MiniBatchKMeans(n_clusters=K,\n",
    "                           random_state=0,\n",
    "                           batch_size=100000,\n",
    "                           max_iter=10).fit(X) # we run MiniBatchKMeans() from sklearn.\n",
    "        c = kmeans.labels_\n",
    "        colors = kmeans.cluster_centers_\n",
    "        print(\"Mini-batch sklearn k-means operation took: \",round(time.perf_counter()-start),\"s\")\n",
    "        \n",
    "        c = np.array(c, dtype=np.uint8)\n",
    "        X_reconstructed = np.array(colors[c, :] * 255, dtype=np.uint8).reshape((w, h, d))\n",
    "        compressed_image = Image.fromarray(X_reconstructed)\n",
    "        \n",
    "        compressed_image.save(destinationPath+\"/\"+str(count)+\".png\")\n",
    "\n",
    "    # after the current image has been processed and saved, we increment the progress counter\n",
    "    count += 1\n",
    "    # display progress\n",
    "    print(\"Progress = \",round(100*count/maxCount),\"%\") \n",
    "\n",
    "# Once all images have been processed...\n",
    "tf = time.perf_counter() # record final time\n",
    "print(\"Total Runtime: \",round(tf-ti),\"s\") # print final runtime (Compliance to requirement [4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion\n",
    "Let's compare the performances of the different image compression stratgies.\n",
    "\n",
    "Performances in terms of run time and compression factor are compared in the table below when run on 5 images, with a total of 16 Mo, and for k=32 colors when clustering is used. We can see that SO strategy is very fast (2s) in comparison to the other technics (>30s). This is because we do not run any clustering algorithm. When clustering is employed, it is much slower but the compression factor achieved are almost 4 times greater. Among clustering strategies, Mini-batch k-means is the fastest of all.\n",
    "<img src=\"img4.png\">\n",
    "\n",
    "Among cluster-based strategies, we can compare the output images. It actually appears that differencce between clustered images is negligeable. Feel free to play around with the code to figure it out. Below, we provide a couple of examples of image compressed using Mini-batch.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ORIGINAL IMAGE**\n",
    "The challenge for reducing this image is the variety of colors (many levels of red, blue, and green) that needs to be encoded in only a few (32 colors).\n",
    "<img src=\"img5.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPRESSED IMAGE (Mini-Batch K-means)**\n",
    "\n",
    "<img src=\"img6.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ORIGINAL IMAGE**\n",
    "The challenge for compressing the following image is the webb which is made of very thin strips of pixels.\n",
    "<img src=\"img7.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPRESSED IMAGE (Mini-Batch K-means)**\n",
    "\n",
    "<img src=\"img8.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Futur Work and improvement:\n",
    "As a futur work, we suggest the following improvement:\n",
    "- Ask user the pixel-skipping step, or;\n",
    "- Ask user the final image size to generate compressed images of the the same size;\n",
    "- Make a notebook which describes the project;\n",
    "- (optional) Add progress bar with tqdm library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
